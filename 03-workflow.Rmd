# Data Management Workflow {#workflow}

This section is in two parts to first describe a workflow that we use internally at TBEP to manage our data and then to describe a road map for opening internal or external datasets at your own organization.  The first section expands on our philosophy for using open science to manage data, including specific workflows we use, as context to the second section.  Our approach is one way of applying open science to managing data.  Applying the same approach at your organization may or may not be appropriate depending on your internal and external needs for managing data.  As such, our approach is generalizable and modular - any of the approaches can be modified in part or together for your own needs. 

## The TBEP approach

### Our philosophy {#philo}

Sections \@ref(opengeneral) and \@ref(philogeneral) introduced you to our basic philosophy and approach to managing data at TBEP.  As an organization that facilitates science, management, and outreach activities among our local partners, we adopt open science as a cornerstore strategy that will serve the Program's core values.  This approach is made explicit in our [Strategic Plan](https://drive.google.com/file/d/11xohuoaHDxNHRqgXoOHdI37FpWvac_rn/view?usp=sharing) that describes how we achieve programmatic goals defined under our [Comprehensive conservation and Management Plan](https://indd.adobe.com/view/cf7b3c48-d2b2-4713-921c-c2a0d4466632) (CCMP) and who we can work with in our [Interlocal Agreement](https://drive.google.com/file/d/1iJcWxmc5SeyDTqiCQ3MLQGWEY_EDGtZT/view?usp=sharing) to help us achieve our goals. 

Our data [Quality Management Plan](https://drive.google.com/file/d/1DyA0PNHV8rEXGMwGiyS7sXY1ECLYpJJO/view) (QMP, @tbep1620) is a companion document to this SOP that ensures the data used by TBEP for decision-making has known and documented quality and is being used appropriately. The QMP establishes an internal process for verifying data quality standards that conform with federal requirements we have as an organization funded in part by federal dollars under Section 320 of the [Clean Water Act](https://www.epa.gov/laws-regulations/summary-clean-water-act).  On the other hand, this SOP is a more hands-on and accessible document that describes a how-to approach for data management that we adopt as an organization.  The SOP goes beyond the QMP by exposing the process and ideas behind how we manage data at TBEP so that others can learn from our experience.  We encourage you to also view our QMP to understand the literal benchmark we use to ensure quality of our data.

We actively work to apply open science to every activity we pursue to achieve our goals under the CCMP.  Open science is a philosophy and set of tools to make research reproducible and transparent, in addition to having long-term value through effective data preservation and sharing [@Beck20].  We use a definition from the [Creative Commons](https://creativecommons.org/about/program-areas/open-science/) for open science as:

> Practicing science in such a way that others can collaborate and contribute, where research data, lab notes and other research processes are freely available, under terms that enable reuse, redistribution and reproduction of the research and its underlying data and methods

There are a couple key words from the definition that we can extract - collaborate, contribute, reuse, redistribute, reproduce.  These concepts channel some of the ideas described by the FAIR principles (section \@ref(fair)).  We can further elaborate on these key words by defining open science as a set of four core principles (Dan Gezelter <http://openscience.org/what-exactly-is-open-science/>. 

1. Transparency in experimental methods, observations, and collection of data.
1. Public availability and reusability of scientific data.
1. Public accessibility and transparency of scientific communication. 
1. The use of web-based tools to facilitate scientific collaboration and reproducibility.

Why is this so important?  Environmental science is very much in the business of applied science, meaning that research that is conducted to develop an understanding of the environment can be used to support the protection and management of a resource.  We need to understand a problem before we can pursue actions to remedy a problem, especially if the wrong decision can be costly.  Active and useful channels of communication must exist for the lessons learned from science to be applied to real world problems.  Applied science can be facilitated with open science to create these channels. 

Without getting too much into the history of how insular practices among academics have contributed to closed science, it's useful to briefly discuss some of reasons why science may not be translated into action.  As a generalization, researchers are trained to study and document details.  Progress in science is based on 1) an intimate understanding of details that guide process and  2) convincing your peers through rigorous review that you actually understand the details you claim to understand.  As a result, we catalog progress in ways that are true to the scientific process, often as dense texts with every last detail noted.  Many researchers not being taught otherwise will often assume that this is an effective way to communicate scientific results to non-scientists.  What we don't realize is that those that need this information to make decisions do not communicate this way because they are not in the business of scientific discovery. Unless they have a personal interest, they don't care about the science behind the decision, only that the science is right to justify the decision.  The most ineffective approach for a scientist to inform environmental management is to deliver a dense 500 page report and assume it provides an effective vehicle for an environmental manager to make a rational decision.  This is not applied science - it is "implied science" because we implicitly decide that our conventional modes of scientific communication will influence managment or policy. 

In addition to communication barriers, other challenges to applied science include irreproducible results, information loss, inaccessible data, and opaque workflows (section \@ref(whymanage), Figure \@ref(fig:divide)).  These challenges affect how science is delivered to decision-makers, how much trust a decision-maker can have in the science behind the decision, and how likely the science can be used as a springboard for more science.  Effective data management as a subset of the broader principles of open science can help bridge the "research-management divide" and help develop continuity of scientific products that can benefit the larger research community.    

```{r divide, out.width = '80%', fig.cap = "Challenges to bridging the divide between scientific products created in research and informed decisions for environmental management.", fig.align = 'center', echo = F}
knitr::include_graphics('img/divide2.png')
```

### The open science cake

Truly applied science facilitated by open science allows for research results or data to connect with different audiences along a spectrum.  It allows research to be shared with other researchers, be connected with decision-makers, and be accessible to the general public.  Where an individual consumes scientific information along the spectrum depends on their interest, need, or level of background knowledge about a subject.  A solid technical foundation is a prerequisite for sharing information and open science methods allow various elements of the research foundation to be accessible to different end users.  We meet our audience where they're at, rather than assuming they can find their way to the details they need. 

We can describe this metaphor as the __open science cake__ (figure \@ref(fig:cake)).  We use this metaphor because everybody loves cake and it conveniently describes our philosophy to delivering science in an applied context.  This delicious cake is a gradient of information from top to bottom.  At the top, the information is more general (e.g., educational material for public consumption) or can be used to inform action (e.g., what needs to be done to remedy a problem).  At the bottom, the information has specificity and forms the foundation for generality or action.  The bottom of the cake is large, reflecting the decades of research and technical resources that are available to inform the management of Tampa Bay (our [library](http://tbep.org/library), for example).  The bottom also includes resources that can be used to springboard additional research, such as analysis code and source datasets.  Individuals at the top of the cake probably don't want a slice at the bottom, but the slice they take from the top would not exist without support from the bottom.

```{r cake, fig.cap = 'The open science cake showing the connection between research, environmental decisions, and the public.'}
knitr::include_graphics('img/cake.png')
```

Most of our partners that we work with are professionals from resource management or local government agencies that have some vested interest in the protection and restoration of Tampa Bay.  This is our primary audience that we can inform for decision-making.  Broadly speaking, this is the audience that needs distilled information from research products but with a level of specificity that goes beyond education materials.  These individuals are in the middle of the cake and the slices they take are actionable science products, such as interactive dashboards, automated report cards, and other decision support tools.  The middle part of the cake is where conventional science becomes truly applied science.

The cake also emphasizes a vertical connection among the layers that allows an individual to take a slice as high or as low in the cake as they want.  This is a critical principle of open science that speaks to accessibility of information at all levels of the scientific process.  Most of the time, an individual will take a slice from the cut at the level that's appropriate for their needs.  However, we want our science (and data) to be transparent and accessible under the FAIR principles and someone can take a slice at a different level if they have a need to do so.  This also speaks to developing a community of practice for open science - access to the tools and the ability to use them to reproduce or expand on existing products.  

Our web products on the [data visualization](https://tbep.org/our-work/data-vizualization/) section of our web page allow an individual to take slices of the cake at different levels.  The website is setup as a series of cards (cakes) for each reporting product that act as an entryway (top of the cake) to different levels of the cake.  If someone clicks on the [Water Quality Report Card](https://tbep.org/water-quality-report-card/) for example, they get to a web page that has very general information about the reporting product and links to our [summary pdf](https://drive.google.com/file/d/124FXmLcXKYUf3ktaVOvFejndiPS0m7K7/view?usp=sharing) that distills over forty years of water quality data for the Bay.  There are links on the right side of the page that provide access to the building blocks of the report card, including the online dashboard, source code for the report card, build status of the report (more on this in section \@ref(automation), citable DOI, and technical documents that describe the science behind our water quality assessment approach.  These links provide the path to the lower levels of the cake.    

### How is connectivity achieved? {@automation}

* General workflow - source to product, figure \@ref(fig:osworkflow)

```{r osworkflow, fig.cap = 'The TBEP open science workflow connecting source data to decision-support products.'}
knitr::include_graphics('img/os-workflow.png')
```

### Tools we use {#tools}

* R/RStudio IDE workflow
     * The tbeptools package as central component
     * How does the package facilitate the above?
* GitHub as a collaborative tool and quasi-archive
     * version control
     * collaborative tool to work together - issues, pull requests
     * DOI through Zenodo
     * CI/CD, Automation with GitHub Actions and badges
     * GitHub linkage to TBEP website

## How can you manage data? {#howyou}

Ten simple rules for creating a good data management plan: https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1004525

* Section is written as a road map for developing a data product, there will be steps/checkboxes/forms, roughly following figure \@ref(fig:dataworkflow)

```{r dataworkflow, fig.cap = 'A hypothetical and generalized timeline for managing data associated with a project.', out.width = '80%'}
knitr::include_graphics('img/dataworkflow.png')
```

* Modularity is key to reproducibility, it is independent of where you're at in the project
* Setup some kind of flow chart (if this, then that)

### I'm at the beginning of my project

* What type of project am I working on? 
* What types of products am I expecting?
* Which datasets are important? Guidance for determining which datasets are important are expressed in great detail in section \@ref(keys).
* How do I want to make the data accessible?
* What QA protocols should be established?

### I'm somewhere in the middle of my project

* Have I collected data?
* Are my data in tidy format (if tabular)? 
* Have I been documenting metadata? 

### I'm at the end of my project

* Time for damage control

### Metadata workflow

* USGS resources <https://www.usgs.gov/products/data-and-tools/data-management>
* Metadata questionnaire <https://prd-wret.s3-us-west-2.amazonaws.com/assets/palladium/production/atoms/files/MetadataQuestionnaire_508compliant.pdf>
* Data dictionaries <https://www.usgs.gov/products/data-and-tools/data-management/data-dictionaries>

### Let's get it online!

* How to of where do you put your data
