# Data Management Workflow {#workflow}

This section is in two parts to first describe a workflow that we use internally at TBEP to manage our data and then to describe a road map for opening internal or external datasets at your own organization.  The first section expands on our philosophy for using open science to manage data, including specific workflows we use, as context to the second section.  Our approach is one way of applying open science to managing data.  Applying the exact same approach at your organization may or may not be appropriate depending on your internal and external needs for managing data.  As such, our approach is generalizable and modular - any of the approaches can be modified in part or together for your own needs. 

## The TBEP approach

### Our philosophy {#philo}

Sections \@ref(opengeneral) and \@ref(philogeneral) introduced you to our basic philosophy and approach to managing data at TBEP.  As an organization that facilitates science, management, and outreach activities among our local partners, we adopt open science as a cornerstore strategy that will serve the Program's core values.  This approach is made explicit in our [Strategic Plan](https://drive.google.com/file/d/11xohuoaHDxNHRqgXoOHdI37FpWvac_rn/view?usp=sharing) that describes how we achieve programmatic goals defined under our [Comprehensive conservation and Management Plan](https://indd.adobe.com/view/cf7b3c48-d2b2-4713-921c-c2a0d4466632) (CCMP) and who we can work with in our [Interlocal Agreement](https://drive.google.com/file/d/1iJcWxmc5SeyDTqiCQ3MLQGWEY_EDGtZT/view?usp=sharing) to help us achieve our goals. 

Our data [Quality Management Plan](https://drive.google.com/file/d/1DyA0PNHV8rEXGMwGiyS7sXY1ECLYpJJO/view) (QMP, @tbep1620) is a companion document to this SOP that ensures the data used by TBEP for decision-making has known and documented quality and is being used appropriately. The QMP establishes an internal process for verifying data quality standards that conform with federal requirements we have as an organization funded in part by federal dollars under Section 320 of the [Clean Water Act](https://www.epa.gov/laws-regulations/summary-clean-water-act).  On the other hand, this SOP is a more hands-on and accessible document that describes a how-to approach for data management that we adopt as an organization.  The SOP goes beyond the QMP by exposing the process and ideas behind how we manage data at TBEP so that others can learn from our experience.  We encourage you to view our QMP to understand the literal benchmark we use to ensure quality of our data.

We actively work to apply open science to every activity we pursue to achieve our goals under the CCMP.  Open science is a philosophy and set of tools to make research reproducible and transparent, in addition to having long-term value through effective data preservation and sharing [@Beck20].  We use a definition from the [Creative Commons](https://creativecommons.org/about/program-areas/open-science/) for open science as:

> Practicing science in such a way that others can collaborate and contribute, where research data, lab notes and other research processes are freely available, under terms that enable reuse, redistribution and reproduction of the research and its underlying data and methods

There are a couple key words from the definition that we can extract - collaborate, contribute, reuse, redistribute, reproduce.  These concepts channel some of the ideas described by the FAIR principles (section \@ref(fair)).  We can further elaborate on these key words by defining open science as a set of four core principles (Dan Gezelter <http://openscience.org/what-exactly-is-open-science/>. 

1. Transparency in experimental methods, observations, and collection of data.
1. Public availability and reusability of scientific data.
1. Public accessibility and transparency of scientific communication. 
1. The use of web-based tools to facilitate scientific collaboration and reproducibility.

Why is this so important?  Environmental science is very much in the business of applied science, meaning that the research that is conducted to develop an understanding of the environment can be used to support the protection and management of a resource.  We need to understand a problem before we can pursue actions to remedy a problem, especially if the wrong decision can be costly.  Active and useful channels of communication must exist for the lessons learned from science to be applied to real world problems.  Applied science can be facilitated with open science. 

Without going into the history of how insular practices among academics have contributed to closed science, it's useful to briefly discuss some of reasons why science may not be translated into action.  Researchers are trained in details.  Progress in science is based on 1) an intimate understanding of process and  2) convincing your peers through rigorous review that you do actually understand the things you claim to understand.  As a result, we catalog progress in ways that are true to the scientific process, often as dense texts with every last detail noted.  Many researchers not being taught otherwise will often assume that this is an effective way to communicate scientific results.  What we don't realize is that those that need this information to make decisions do not communicate this way because they are not in the business of scientific discovery. Unless they have a personal interest, they don't care about the science behind the decision, only that the science is right to justify the decision.  The most ineffective approach for a scientist to inform environmental management is to deliver a dense 500 page report and assume it provides an effective vehicle for an environmental manager to make a rational decision.  This is not applied science - it is "implied science". 

In addition to communication barriers, other challenges to applied science include irreproducible results, information loss, inaccessible data, and opaque workflows (section \@ref(whymanage), Figure \@reF(fig:divide)).  These challenge relate to how science is delivered to decision-makers, how much trust a decision-maker can have in the science behind the decision, and how likely the science can be used as a springboard for more science.  Effective data management as a subset of the broader principles of open science can help bridge the "research-management divide" and help develop continuity of scientific products that can benefit the larger research community.    

```{r divide, out.width = '80%', fig.cap = "Challenges to bridging the divide between scientific products created in research and informed decisions for environmental management.", fig.align = 'center', echo = F}
knitr::include_graphics('img/divide2.png')
```

### The open science cake


* The Open Science cake: what it is, how we do we implement it, and what does it mean for data management, figure \@ref(fig:cake)

```{r cake, fig.cap = 'The open science cake showing the connection between research, environmental decisions, and the public.'}
knitr::include_graphics('img/cake.png')
```

* Applied science, not implied science
* General workflow - source to product, figure \@ref(fig:osworkflow)

```{r osworkflow, fig.cap = 'The TBEP open science workflow connecting source data to decision-support products.'}
knitr::include_graphics('img/os-workflow.png')
```

### Tools we use {#tools}

* R/RStudio IDE workflow
     * The tbeptools package as central component
     * How does the package facilitate the above?
* GitHub as a collaborative tool and quasi-archive
     * version control
     * collaborative tool to work together - issues, pull requests
     * DOI through Zenodo
     * CI/CD, Automation with GitHub Actions and badges
     * GitHub linkage to TBEP website

## How can you manage data? {#howyou}

Ten simple rules for creating a good data management plan: https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1004525

* Section is written as a road map for developing a data product, there will be steps/checkboxes/forms, roughly following figure \@ref(fig:dataworkflow)

```{r dataworkflow, fig.cap = 'A hypothetical and generalized timeline for managing data associated with a project.', out.width = '80%'}
knitr::include_graphics('img/dataworkflow.png')
```

* Modularity is key to reproducibility, it is independent of where you're at in the project
* Setup some kind of flow chart (if this, then that)

### I'm at the beginning of my project

* What type of project am I working on? 
* What types of products am I expecting?
* Which datasets are important? Guidance for determining which datasets are important are expressed in great detail in section \@ref(keys).
* How do I want to make the data accessible?
* What QA protocols should be established?

### I'm somewhere in the middle of my project

* Have I collected data?
* Are my data in tidy format (if tabular)? 
* Have I been documenting metadata? 

### I'm at the end of my project

* Time for damage control

### Metadata workflow

* USGS resources <https://www.usgs.gov/products/data-and-tools/data-management>
* Metadata questionnaire <https://prd-wret.s3-us-west-2.amazonaws.com/assets/palladium/production/atoms/files/MetadataQuestionnaire_508compliant.pdf>
* Data dictionaries <https://www.usgs.gov/products/data-and-tools/data-management/data-dictionaries>

### Let's get it online!

* How to of where do you put your data
