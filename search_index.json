[["index.html", "Data Management SOP for the Tampa Bay Estuary Program Section 1 Overview 1.1 Contributing to this document 1.2 About", " Data Management SOP for the Tampa Bay Estuary Program Marcus W. Beck, Gary E. Raulerson 2021-01-14 Section 1 Overview Welcome to the Tampa Bay Estuary Program Data Management SOP. This document describes our philosophy for managing data used by our program and serves as motivation for our external partners to become stewards of their own data. Working together, we can improve how data are used to support the continued protection and restoration of Tampa Bay. 1.1 Contributing to this document Using an open science ethos, we strongly encourage community collaboration in how this document evolves. This means anybody can contribute directly to content in this document. Please follow the guidelines in section 1.1 to learn how to contribute and improve this SOP. This SOP was created using bookdown, which is an approach to creating long-form documents with RMarkdown. The source code is available on the TBEP GitHub group web page: https://github.com/tbep-tech/data-management-sop. Each section is a plain .Rmd text file that can be edited or commented to provide feedback on content. There are several ways you can contribute to or edit this document. Before you choose your editing option, you should be comfortable with Git/GitHub basics and have some working knowledge of RMarkdown files (but see 1.1.4). The first step is to make sure you have a GitHub account so you can edit the files. Jenny Bryan’s Happpy Git and GitHub for the useR is an excellent resource to get started with version control. R Markdown: The Definitive Guide is a great resource for learning RMarkdown (also see the cheatsheet). 1.1.1 Option 1 Requires: GitHub account, write access to the source code repository Each section can be edited directly by selecting the edit button at the top of the page. Clicking on the edit button will take you to GitHub, where you will see an edit page like this: Each edit page is specific to the section where you’ve selected the edit button, e.g., if you click the edit button for section 2, you’ll be sent to the edit page for the .Rmd file for section 2. Feel free to make any changes on the .Rmd file. When you’re done, scroll to the bottom and “commit” your changes. This simply means you write a few words describing the edits you’ve made. Be as succinct as possible. When you’re done, hit the green “Commit changes” button. 1.1.2 Option 2 Requires: Github account Follow the above steps in 1.1.1 by navigating to a section you’d like to edit on this website and selecting the edit button. If you don’t have write access to the repository, you will see something like this: This simply means that you need to create your own copy to edit. You can fork your own copy to your personal account and make your edits there. Once editing is done, you can submit a pull request to the original repository with your proposed changes. Not sure what this means? Check out this chapter here: https://happygitwithr.com/fork-and-clone.html 1.1.3 Option 3 Requires: GitHub account If none of the above sounds appealing, you can always post any suggestions or edits as an issue under the issues tab of the repository. When you create a new issue by clicking the giant green “New issue” button, you’ll see something like this: Give your issue a short but informative title (e.g., “suggests edits to section 2”). Under the “Write” tab, explain what edits or changes you’d like to see. Feel free to select a member of the TBEP staff to assign the issue using the menu on the right. The issues descriptions support Markdown syntax, so get creative in your descriptions (i.e., make lists, link to documents, etc., see the cheatsheet). In general, one issue should cover only one suggested change to the document. However, multiple text edits to the same document can be submitted to the same issue so long as they cover similar topics, e.g., one issue for several suggested edits to one section. 1.1.4 Option 4 Requires: Email Just email me any changes you’d like to see! 1.2 About The Tampa Bay Estuary Program is one of 28 National Estuary Programs designated by Congress to restore and protect “estuaries of national significance.” Administered by the U.S Environmental Protection Agency under the Clean Water Act, each program must develop a science-based plan using community input to protect and enhance the natural resources of its respective estuary and surrounding watershed. The Comprehensive Conservation and Management Plan (CCMP, updated in 2017) presents 39 actions to sustain progress in bay restoration through the year 2027. To address the actions in our CCMP, our 2021-2025 Strategic Plan provides a framework to guide decisions about how to align personnel and financial resources with the Program’s mission in ways that maximize our impact on Tampa Bay recovery. A cornerstone strategy of this plan is the use of open science principles and methods to allow the TBEP to be the primary source of trusted, unbiased, and actionable science for the Tampa Bay Estuary. This document is a reflection of these strategies. Please visit our website for additional information about our program: https://www.tbep.org This book is licensed under a Creative Commons Attribution 4.0 International License. This version of the book was built automatically with GitHub Actions on 2021-01-14. "],["background.html", "Section 2 Background 2.1 Importance of data 2.2 Why we need to effectively manage data 2.3 The TBEP philosophy 2.4 Goals/objectives of this document", " Section 2 Background 2.1 Importance of data Data supports research, research supports environmental management A data definition, e.g., raw information in flat files, synthesized/derived datasets, models, etc. How data are used in applied research/environmental sciences Research products support management frameworks, research products are data Monitoring programs produce data to track progress in achieving management goals Data and processes behind decision-support tools may be opaque 2.2 Why we need to effectively manage data What happens when data are not managed properly Loss of information over time, Figure 2.1 Lack of trust in the process Increased siloing Increased costs Figure 2.1: Loss of information over time in the absence of data management (Michener et al. 1997) Bit rot, link rot (Vines et al. 2014) Professorware (Mons 2018) - objects that address a novel intellectual challenge, a critical aspect of research (academic or industry) required for incremental progress, but lacking support (i.e., not scalable or sustainable). This is problematic when these tools are embedded into larger workflows (insert post-doc bakery meme) Benefits of a data management workflow Applications in open science 2.3 The TBEP philosophy How TBEP is using open science to manage internal/external data and how is this increasing transparency, reproducibility, and efficiency of our reporting products TBEP Open Science Subcommittee, building the community of practice 2.4 Goals/objectives of this document Goal: Motivate internal staff and external partners to become stewards of their data by demonstrating the value of open data practices and providing a road map to achieving this goal. Link to QMP (E.T. Sherwood, G. Raulerson, M. Beck, M. Burke 2020) and distinction between the documents What it is, what it is not - including what makes TBEP different from other organizations, i.e., we have hands in lots of projects vs one central product (e.g., OHI), so our SOP needs to be generalizable It is: An overview document explaining the TBEP approach to data management, explains philosophy in details, tools we have developed It is: A cookbook describing how to manage datasets in an open science framework, including considerations before, during, and after a project, with full realization that data management should begin during project planning but often does not It is not: A definitive overview of best practices for data management It is not: A definitive overview of available online services for opening data, but we lean towards use of specific platforms that we find useful Intended audience: TBEP internal staff and external partners, targeted towards technical staff in the latter case while also appealing to managers/admin that can create space to foster better practices for data management, also see TBEP QMP sec 1.3 Document structure References "],["keys.html", "Section 3 Key Concepts and Principles 3.1 General concepts 3.2 Specific concepts", " Section 3 Key Concepts and Principles Before we get started, we need to discuss some basic ideas around data and their management. Understanding these concepts and why they’re important will facilitate the development and curation of open data for others to use - it will save you time in the future. We start first with general concepts and then dive into some detailed concepts that may seem daunting but are important when considering how best to manage data. 3.1 General concepts What are data, i.e., from the perspective of the researcher/agency scientist/manager? A workflow (e..g, operationalizing Twitter scraping), dataset (field/lab data), model products, etc. Ask yourself, who is going to use this and how do I make their (my) lives “easier” by opening the data using FAIR principles? OPEDAS (Mons 2018) - other people’s data and services - this is critical to TBEP that depends on partner data for reporting What is open data? The FAIR principles (very broad, emphasize throughout), also general open science definition and how data relates to open science (channel PeerJ paper distinction Beck et al. (2020)) What is metadata and why do we need it? Best practices for QA 3.2 Specific concepts Types of data products (e.g., raw data, models, synthesized/derived data, etc.) or types of data (flat file, spatial, disparate) Tabular data an overview of tidy data, can a machine read it? The wrong approach Basic database principles logical extension of tidy data normalized tables (including discussion of key variables), what are unique ids (e.g., tberf oyster, how did I make the unique id?), facilitate standard DB queries Metadata principles Why? Supports the F in FAIR, also supports use by others Minimum requirements Formal standards data dictionaries, naming conventions Where do data live long-term, what’s a doi, considering a data paper, federated repository, etc. The A in FAIR GitHub repository Stable URL Official repository References "],["workflow.html", "Section 4 Data Management Workflow 4.1 The TBEP approach 4.2 How can you manage data?", " Section 4 Data Management Workflow This section describes our approach to managing data internally, to help describe what we do and why we do it. This is context for section 4.2 that provides a road map for opening internal or external datasets. 4.1 The TBEP approach 4.1.1 Our philosophy The TBEP data QMP (E.T. Sherwood, G. Raulerson, M. Beck, M. Burke 2020): what, why, how The Open Science cake: what it is, how we do we implement it, and what does it mean for data management, figure 4.1 Figure 4.1: The open science cake showing the connection between research, environmental decisions, and the public. General workflow - source to product, figure 4.2 Figure 4.2: The TBEP open science workflow connecting source data to decision-support products. 4.1.2 Tools we use R/RStudio IDE workflow The tbeptools package as central component How does the package facilitate the above? GitHub as a collaborative tool and quasi-archive version control collaborative tool to work together - issues, pull requests DOI through Zenodo CI/CD, Automation with GitHub Actions and badges GitHub linkage to TBEP website 4.2 How can you manage data? Section is written as a road map for developing a data product, there will be steps/checkboxes/forms, roughly following figure 4.3 Figure 4.3: A hypothetical and generalized timeline for managing data associated with a project. Modularity is key to reproducibility, it is independent of where you’re at in the project Setup some kind of flow chart (if this, then that) 4.2.1 I’m at the beginning of my project What type of project am I working on? What types of products am I expecting? How do I want to make the data accessible? What QA protocols should be established? 4.2.2 I’m somewhere in the middle of my project Have I collected data? Are my data in tidy format (if tabular)? Have I been documenting metadata? 4.2.3 I’m at the end of my project Time for damage control 4.2.4 Metadata workflow USGS resources https://www.usgs.gov/products/data-and-tools/data-management Metadata questionnaire https://prd-wret.s3-us-west-2.amazonaws.com/assets/palladium/production/atoms/files/MetadataQuestionnaire_508compliant.pdf Data dictionaries https://www.usgs.gov/products/data-and-tools/data-management/data-dictionaries 4.2.5 Let’s get it online! How to of where do you put your data References "],["cases.html", "Section 5 Case Studies 5.1 TBERF oyster restoration project 5.2 DeSoto/RESTORE project 5.3 Red Tide Twitter repo", " Section 5 Case Studies Demonstrate the workflow, identify questions that were asked initially and what does done to answer them 5.1 TBERF oyster restoration project Initial questions - Are we formatting our data correctly? Example of mid-project data curation Emphasis on data dictionary, normalized tables 5.2 DeSoto/RESTORE project Initial questions - how can we fulfill RESTORE requirements for data delivery based on a general grant requirement? Example of continuous stream data Emphasis on CI/CD checks and web products 5.3 Red Tide Twitter repo Initial questions - What are the most relevant products from this project and how can we make them accessible? Example of specific data product with linkage to technical and primary lit publication Emphasis on creating a GitHub repo for archive of lexicon and source data, DOI "],["final.html", "Section 6 Final Words", " Section 6 Final Words emphasis on “something is better than nothing”, fully open is ideal but difficult to achieve Just remember FAIR evolving tools trying to be both a domain expert and data expert will spread you thin (Mons 2018, 27, 36), look to the helpers/community (Figure 6.1) Figure 6.1: Look to the helpers and your open science community! Artwork by @allison_horst. References "],["appendices.html", "Section 7 Appendices 7.1 List of resources 7.2 Data types 7.3 Definitions 7.4 Metadata templates", " Section 7 Appendices 7.1 List of resources 7.2 Data types Field data Survey forms Tabular* Database of tables Database Synthesis New Model Actual model Model results Dashboard 7.3 Definitions Dashboard Data Aggregation vs. synthesis Model Tabular Database Flat file Tidy data 7.4 Metadata templates General - Who, what, when, where, why? Specific - XML, EML, etc. "],["references.html", "References", " References "]]
