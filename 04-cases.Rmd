# Case Studies {#cases}

In this section we describe three case studies to demonstrate how data management workflows are developed in the wild.  In section \@ref(automation), we presented a comprehensive workflow for how we developed our water quality report card.  The examples in this section are similar by adopting elements of the previously described workflow, but with some important differences. The examples here represent data products resulting from TBEP-funded research as opposed to a reporting product and, more importantly, all of the data management workflows for these projects were developed after the projects were started.  This is a no-no scenario for data management, but we provide these examples to demonstrate how we've applied the data management principles in this document in unfortunate but realistic situations. Each example describes the general goals and questions of the project, then outlines the thought process to identifying and documenting important data products.

## TBERF oyster restoration project {#oyster}

Establishment and restoration of oyster reefs in Tampa Bay is a critical programmatic goal defined under our Comprehensive Conservation and Management Plan and Habitat Master Plan Update.  Oyster reefs are formed by the cumulative build up of shell material over time and provide food and habitat, reduce erosion, stabilize shorelines, and improve water quality.  Recreational and commercial harvest of oysters can also provide economic support for the region.  The historical distribution of oyster populations in Tampa Bay is poorly documented, although anecdotal evidence suggests current coverage of oysters Tampa Bay is far less than previously occurred.  Restoration efforts have been used as a fundamental activity to re-establish viable oyster populations in the Bay.  

Critical questions on factors that contribute to the establishment or success of restoration of oyster beds in Tampa Bay need to be answered to achieve our programmatic goals.  This includes information on long-term success of natural and restored sites, including location in the Bay, timing of restoration activities, and preferred restoration materials for varying conditions.  In addition, standardized monitoring protocols for restoration sites to evaluate or estimate long-term success are being developed.  This project involves establishing restoration sites at different locations and collecting field data to address relevant questions. 

At the time of writing, collection of field data for the first year of the project was complete and existing data was provided as multiple spreadsheets in an Excel workbook.  The field data is the most likely candidate for the most important data contribution of this project and a plan for curating these data has recently been developed.  The plan for curating these data is primarily focused on answering questions to identify which factors promote long-term success of oyster reefs, with the intent of formatting the data for analysis to answer the questions and delivering the data in a way to reproduce the results.  Environmental managers (e.g., partners that conduct restoration) may have interest in the results (i.e., analysis outcomes), whereas additional researchers may have an interest in using the raw data to support follow-up analysis or to synthesize the information with other datasets.   

Existing efforts to curate and manage these data have focused on formatting the data in a tidy format.  Because field data collection efforts have already begun, we developed a post-hoc workflow to wrangle the information into flat files with appropriate keys to link data between tables.  Identifying a permanent home for these data and formal documentation of metadata have not been done.  Tidying the data will aid analysis and facilitate documentation and delivery of final data products when the time is right (e.g., sooner rather than later).  In this example, we focus on the steps that were done to tidy the data. 

Our data management workflow is available in a GitHub repository: https://github.com/tbep-tech/tberf-oyster. The raw data are available in a the `data/raw` folder and their processing to make them "tidy" is accomplished through a custom analysis script at `R/dat_proc.R`.  The analysis script converts the raw data present in multiple sheets in the Excel workbook to three separate tables for the site data (e.g., site metadata), water quality data at each site, and oyster data at each site.  We use functions from the dplyr package extensively to extract relevant information from the raw data to create the separate tidy tables.  We also had to discuss ambiguous labels in the data when they were unclear or presented as conflicting information between tables.   

* Screenshot of raw data, then headers of tidy data
* How we made keys
* Site build for analysis

In this example, we emphasize the primary reason between the format of raw data and the resultng tidy data tables, where the former is setup for ease of entry, whereas the latter is setup for ease of analysis.  As noted in section xyz, many datasets exist in a native format because of a disconnect between what's easy to enter by hand and what's easy to analyze.  Entering data in the field in a tidy format (or more likely, by hand from field sheets when you're back in the office) may seem unnatural at irst.  

## DeSoto/RESTORE project {#desoto}

* Initial questions - how can we fulfill RESTORE requirements for data delivery based on a general grant requirement?
* Example of continuous stream data
* Emphasis on CI/CD checks and web products

## Red Tide Twitter repo {#twitter}

* Initial questions - What are the most relevant products from this project and how can we make them accessible?
* Example of specific data product with linkage to technical and primary lit publication
* Emphasis on creating a GitHub repo for archive of lexicon and source data, DOI
